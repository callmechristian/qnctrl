Parameter,Value
uid,e2b51d7e-a213-414a-b174-3d6fde60dac7
date_completed,2024-07-18 11:57:40.706525
algorithm,PPO with continous action gaussian policy
total_episodes,400
seed,<environment.models.simple_control_fixed.SimpleControlledFixedEnv object at 0x7fde2a4c7a60>
gamma,0.99
lambda,0.99
num_actions,2
num_states,30
HIDDEN_LAYER_SIZES,"(256, 256)"
target_kl,0.01
train_policy_iterations,180
train_value_iterations,180
max_env_steps,100
latency,10
policy_learning_rate,0.0003
value_function_learning_rate,0.001
clip_ration,0.1
env_reward_type,negative
env.delta_t,0.1
env.max_t,10.0
env_type,SimpleControlledFixedEnv
env.fixed_errors_flags,"[True, True, True, True, False, False, True, True, True, True, True, True]"
env.fixed_error_ctrl_pump,"[0, 0, 0, 0]"
env.fixed_error_ctrl_alice,"[0, 0, 0, 0]"
env.fixed_error_ctrl_bob,"[0, 0, 0, 0]"
total_training_time,337.64829444885254
avg_time_per_ep,28.137357870737713
baseline_reward,-62.11419558673205
convergence_reward,-22.870231513466052
note,curriculum: restrict QBER to X then Z then both
