{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor:\n",
    "    def __init__(self, input_dim, output_dim, lr):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.lr = lr\n",
    "        self.hidden_dim = 32\n",
    "        self.model = self._build_model()\n",
    "        def adv_baseline_loss(y_true, y_pred):\n",
    "            # Calculate the advantage\n",
    "            advantage = y_true - y_pred\n",
    "\n",
    "            # Calculate the policy loss\n",
    "            policy_loss = -tf.math.log(y_pred) * tf.stop_gradient(advantage)\n",
    "\n",
    "            # Calculate the baseline loss\n",
    "            baseline_loss = tf.reduce_mean(tf.square(advantage))\n",
    "\n",
    "            # Calculate the total loss\n",
    "            total_loss = policy_loss + baseline_loss\n",
    "\n",
    "            return total_loss\n",
    "        \n",
    "        self.model.compile(loss=adv_baseline_loss, optimizer=Adam(learning_rate=self.lr))\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(self.hidden_dim, input_shape=(self.input_dim,), activation=\"relu\"))\n",
    "        model.add(Dense(self.hidden_dim, activation=\"relu\"))\n",
    "        model.add(Dense(self.output_dim, activation=\"softmax\"))\n",
    "        return model\n",
    "\n",
    "    def act(self, state):\n",
    "        probs = self.model.predict(state)[0]\n",
    "        action = np.random.choice(range(self.output_dim), p=probs)\n",
    "        return action\n",
    "\n",
    "    def optimizer(self):\n",
    "        # Advantage function (REINFORCE with baseline)\n",
    "        state_pl = self.model.input\n",
    "        action_onehot_pl = Input(name=\"action_onehot\", shape=(None, self.output_dim))\n",
    "        adv_pl = Input(name=\"advantage\", shape=(None,))\n",
    "\n",
    "        pi_pl = self.model.output\n",
    "        pi_vec = tf.reduce_sum(action_onehot_pl * pi_pl, axis=1)\n",
    "        loss_vec = -tf.math.log(pi_vec) * tf.stop_gradient(adv_pl)\n",
    "        loss = tf.reduce_mean(loss_vec)\n",
    "\n",
    "        opt = Adam(learning_rate=self.lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic:\n",
    "    def __init__(self, input_dim, output_dim, lr):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.lr = lr\n",
    "        self.hidden_dim = 32\n",
    "        self.model = self._build_model()\n",
    "        self.train = self.model.compile(loss='mse', optimizer=Adam(learning_rate=self.lr))\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(self.hidden_dim, input_shape=(self.input_dim,), activation=\"relu\"))\n",
    "        model.add(Dense(self.hidden_dim, activation=\"relu\"))\n",
    "        model.add(Dense(1, activation=\"linear\"))\n",
    "        return model\n",
    "\n",
    "    def train(self, S, G):\n",
    "        self.model.train_on_batch([S, G])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = 16\n",
    "        self.lr = 0.001\n",
    "        self.gamma = 0.99\n",
    "\n",
    "        self.states = deque(maxlen=4096)  # Experience replay memory\n",
    "        self.actions = deque(maxlen=4096)\n",
    "        self.rewards = deque(maxlen=4096)\n",
    "\n",
    "        self.actor = Actor(input_dim, output_dim, self.lr)\n",
    "        self.critic = Critic(input_dim, output_dim, self.lr)\n",
    "\n",
    "    def act(self, state):\n",
    "        probs = self.actor.model.predict(state)[0]\n",
    "        print(f\"Shape of probs: {probs.shape}\")  # Debug print statement\n",
    "        probs = np.squeeze(probs)  # Ensure probs is 1-dimensional\n",
    "        action = np.random.choice(range(self.output_dim), p=probs)\n",
    "        return action\n",
    "\n",
    "    def remember(self, state, action, reward):\n",
    "        self.states.append(state)\n",
    "        self.actions.append(action)\n",
    "        self.rewards.append(reward)\n",
    "\n",
    "    def learn(self):\n",
    "        # Sample from memory\n",
    "        S = np.array(self.states)\n",
    "        A = np.array(self.actions)\n",
    "        R = np.array(self.rewards)\n",
    "\n",
    "        # One-hot encode actions\n",
    "        A_onehot = to_categorical(A, self.output_dim)\n",
    "\n",
    "        # Find discounted returns and advantages\n",
    "        G = self.find_discounted_return(R)\n",
    "        V = self.critic.model.predict(S)\n",
    "        V = np.reshape(V, len(V))\n",
    "        Adv = G - V\n",
    "\n",
    "        # Train actor and critic\n",
    "        self.actor.train([S, A_onehot, Adv])\n",
    "        self.critic.train([S, G])\n",
    "\n",
    "        # Clear memory (optional for experience replay)\n",
    "        self.states.clear()\n",
    "        self.actions.clear()\n",
    "        self.rewards.clear()\n",
    "\n",
    "    def find_discounted_return(self, R):\n",
    "        R_discounted = np.zeros_like(R)\n",
    "        running_total = 0\n",
    "        for t in reversed(range(len(R_discounted))):\n",
    "            running_total = running_total * self.gamma + R[t]\n",
    "            R_discounted[t] = running_total\n",
    "        R_discounted -= np.mean(R_discounted)\n",
    "        R_discounted /= np.std(R_discounted)\n",
    "        return R_discounted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from environment.models.simple_control_fixed import SimpleControlledFixedEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SimpleControlledFixedEnv()\n",
    "env.latency = 0\n",
    "env.fixed_error_ctrl_alice = [np.pi/2, 0, 0, 0]\n",
    "env.fixed_error_ctrl_bob = [0, 0, 0, 0]\n",
    "env.fixed_error_ctrl_pump = [0, 0, 0, 0]\n",
    "env.fixed_errors_flags = [True, True, True, True,\n",
    "                          True, True, True, True,\n",
    "                          True, True, True, True,]\n",
    "env.delta_t = 1\n",
    "env.max_t = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2a7aa48b6e0>,\n",
       " <matplotlib.lines.Line2D at 0x2a7aa48bda0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "# print(env.get_done())\n",
    "done = False\n",
    "while not done:\n",
    "    _, _, done = env.step()\n",
    "    # print(done)\n",
    "\n",
    "# print(env.get_done())\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ylim(0, 1)\n",
    "# print(env.get_qber())\n",
    "plt.plot(env.get_qber())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "Episode:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Shape of probs: (3,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Shape of probs: (3,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episode:   0%|          | 0/100 [00:07<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(32, 1, 2), dtype=float32). Expected shape (None, 2), but input has incompatible shape (32, 1, 2)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32, 1, 2), dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m     state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[0;32m     21\u001b[0m     reward_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[1;32m---> 22\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m scores_baseline\u001b[38;5;241m.\u001b[39mappend(reward_sum)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# if e % 100 == 0:\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#     print('episode, reward = {}, {}'.format(e,reward_sum))\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 39\u001b[0m, in \u001b[0;36mAgent.learn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Find discounted returns and advantages\u001b[39;00m\n\u001b[0;32m     38\u001b[0m G \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_discounted_return(R)\n\u001b[1;32m---> 39\u001b[0m V \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcritic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m V \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(V, \u001b[38;5;28mlen\u001b[39m(V))\n\u001b[0;32m     41\u001b[0m Adv \u001b[38;5;241m=\u001b[39m G \u001b[38;5;241m-\u001b[39m V\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\keras\\src\\models\\functional.py:244\u001b[0m, in \u001b[0;36mFunctional._adjust_input_rank\u001b[1;34m(self, flat_inputs)\u001b[0m\n\u001b[0;32m    242\u001b[0m             adjusted\u001b[38;5;241m.\u001b[39mappend(ops\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    243\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input shape for input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but input has incompatible shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    247\u001b[0m     )\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# Add back metadata.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(flat_inputs)):\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(32, 1, 2), dtype=float32). Expected shape (None, 2), but input has incompatible shape (32, 1, 2)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32, 1, 2), dtype=float32)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "input_dim = 2\n",
    "output_dim = 3\n",
    "agent = Agent(input_dim, output_dim)\n",
    "\n",
    "EPISODES = trange(100, desc='Episode: ', leave=True)\n",
    "scores_baseline = []\n",
    "for e in EPISODES:\n",
    "    state, _ = env.reset()\n",
    "    reward_sum = 0\n",
    "    done = False\n",
    "    while not done:\n",
    "        # print(f\"State shape before act: {state}\") \n",
    "        state = tf.convert_to_tensor(state, dtype=tf.float32)\n",
    "        state = tf.expand_dims(state, axis=0)  # Add batch dimension\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done = env.step(a_alice=[action, 0, 0, 0])\n",
    "        agent.remember(state, action, reward)\n",
    "        state = next_state\n",
    "        reward_sum += reward\n",
    "    agent.learn()\n",
    "    scores_baseline.append(reward_sum)\n",
    "    # if e % 100 == 0:\n",
    "    #     print('episode, reward = {}, {}'.format(e,reward_sum))\n",
    "plt.plot(scores_baseline)\n",
    "plt.legend('reward')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
